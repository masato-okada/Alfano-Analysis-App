import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

# CSVファイルを読み込む
def analyze_alfano_data(file_path):
    # データ読み込み
    df = pd.read_csv(file_path)
    
    # 基本情報の確認
    print("データ形状:", df.shape)
    print("\nデータ型情報:")
    print(df.info())
    print("\n基本統計量:")
    print(df.describe())
    
    # 欠損値の確認
    print("\n欠損値の数:")
    print(df.isnull().sum())
    
    # 数値データの相関分析
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    if len(numeric_columns) > 1:
        correlation = df[numeric_columns].corr()
        plt.figure(figsize=(10, 8))
        sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('相関ヒートマップ')
        plt.savefig('correlation_heatmap.png')
        print("\n相関ヒートマップを保存しました")
    
    # クラスタリング分析（数値データがある場合）
    if len(numeric_columns) >= 2:
        # データの標準化
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(df[numeric_columns])
        
        # PCA分析
        pca = PCA(n_components=2)
        pca_result = pca.fit_transform(scaled_data)
        
        # KMeans クラスタリング
        kmeans = KMeans(n_clusters=3, random_state=42)
        cluster_labels = kmeans.fit_predict(scaled_data)
        
        # 結果の可視化
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='viridis')
        plt.colorbar(scatter)
        plt.title('Alfanoデータのクラスタリング結果')
        plt.xlabel('PCA 第1主成分')
        plt.ylabel('PCA 第2主成分')
        plt.savefig('clustering_result.png')
        print("\nクラスタリング結果を保存しました")
        
        # クラスタ別の特徴
        df['cluster'] = cluster_labels
        print("\nクラスタ別の統計情報:")
        print(df.groupby('cluster').mean())
    
    # 分析結果をJSONとして保存（Next.jsでの利用のため）
    result = {
        'summary': {
            'rows': df.shape[0],
            'columns': df.shape[1],
            'missing_values': df.isnull().sum().sum()
        },
        'columns': df.columns.tolist(),
        'data_sample': df.head(5).to_dict('records')
    }
    
    if len(numeric_columns) >= 2:
        result['clusters'] = {
            'count': len(np.unique(cluster_labels)),
            'sizes': pd.Series(cluster_labels).value_counts().to_dict(),
            'cluster_means': df.groupby('cluster').mean().to_dict()
        }
    
    return result

# 使用例
if __name__ == "__main__":
    results = analyze_alfano_data("alfano_data.csv")
    
    # 結果をJSONとして保存
    import json
    with open('analysis_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print("\n分析結果をanalysis_results.jsonに保存しました")